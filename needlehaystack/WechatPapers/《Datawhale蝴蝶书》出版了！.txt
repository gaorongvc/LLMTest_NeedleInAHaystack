《Datawhale蝴蝶书》出版了！                          AIGC开放社区              AIGC开放社区微信号AIGCOPEN功能介绍专注AIGC领域的专业社区，关注微软OpenAI、百度文心一言、讯飞星火等大语言模型（LLM）的发展和应用落地，聚焦LLM的市场研究和AIGC开发者生态，欢迎关注！专注AIGC领域的专业社区，关注微软&OpenAI、百度文心一言、讯飞星火等大语言模型（LLM）的发展和应用落地，聚焦LLM的市场研究和AIGC开发者生态，欢迎关注！ Datawhale干货 作者：Datawhale开源项目团队随着ChatGPT的爆火，我们相信未来会有越来越多的大模型及类似OpenAI提供的服务出现，AI 正在逐渐平民化，将来每个人都可以利用大模型轻松地做出自己的AI产品。于是“蝴蝶书”——《ChatGPT原理与应用开发》应运而生！“蝴蝶书”源自Datawhale开源项目HuggingLLM，GitHub 2K+星、B站播放量超30万，也有幸得到吴飞、周明、朱信忠、金耀辉、张俊林等大咖老师的推荐。同时，在人民邮电出版社的支持下，继“南瓜书”“蘑菇书”“熊猫书”之后，推出了第4本系列纸质书。我们开源项目 HuggingLLM的初心，正是因为我们相信正在经历一个伟大的时代，我们相信这是一个值得每个人全身心拥抱的时代，我们更加相信这个世界必将会因此而变得更加美好。一、从开源到出版从李沐开源的《动手学深度学习》，邱锡鹏的《神经网络与深度学习》，再到Datawhale的《南瓜书》、《Easy RL：强化学习教程》出版，让知识回归大众，让大众有机会和行业精英一样为社会做出贡献，是Datawhale开源内容的探索性意义。从开源到出版，带来的收入其实不高，但让开源贡献者被大众认可是促使开源良性循环的重要一环，会促使国内的开源氛围变好，让更多人受益。确切地说，这是一本拥抱时代的书“蝴蝶书”力图帮助大家降低门槛，缩小应用程序和研究之间的差距，使得大模型应用开发变得触手可及。它是一本面向有一定编程基础或实际项目（不一定是算法）经历，对 ChatGPT（或类似模型）感兴趣、想利用相关技术做一些新产品或应用的学习者的书籍，旨在利用 ChatGPT API 开发相关应用。期望把方法传播给更多人，期望新技术的突破能够更多地改善我们所处的世界。这是一本强调知识应用和实践重要性的书洛克菲勒说过：“真正重要的不在于有多少知识，而在于如何使用现有的知识。知识只是潜在的力量，只有将其付诸应用，而且是建设性的应用，才会显示出它的威力”。“蝴蝶书”围绕着任务展开，很多设计思路和细节其实可以应用在多个领域。我们再次强调，期望学习者能够多多实践，多多应用。这是一本完全根据学习经历编著而成的书这本书是编著者基于自己在自然语言处理领域的学习经历精心编写的。它不仅分享了编著者在探索大型语言模型（LLM）如ChatGPT时遇到的挑战和解决方案，还提供了宝贵的经验，帮助初学者避免常见的陷阱。编著者认为，深入理解机器学习原理的最佳途径是通过公式推导，这也是编著者在学习过程中的亲身体验。这本书的编写初衷是为了让更多人，尤其是非专业人士，能够利用这一新兴技术，推动行业的创新和发展。通过分享编著者的个人学习经历和对知识深刻理解的追求，这本书旨在激发读者的共鸣，鼓励他们在自己的学习旅程中探索和成长。二、感谢老师们的鼓励和支持感谢吴飞、周明、朱信忠、金耀辉、张俊林5位人工智能领域大咖的亲笔推荐。“这本书是由Datawhale所推出的力作，秉承了Datawhale‘为了学习者’的一贯理念，基于志愿者团队精彩的开源学习内容精心编纂而成，深入浅出地介绍大语言模型的原理和工程实践，对于初学者了解ChatGPT非常有帮助！”——吴飞 浙江大学人工智能研究所所长“书中内容围绕自然语言处理任务展开，很多设计思路和细节其实可以应用到多个领域。期望读者多学多练，能够在实践中提升自我。”——周明 澜舟科技创始人兼CEO创新工场首席科学家“这本书虽然以ChatGPT作为示例，但绝大部分内容都可以无缝切换为其他大语言模型。这得益于本书基于以‘自然语言处理算法任务’为核心的设计理念，因而这本书具有更长的生命周期。”——朱信忠 浙江师范大学人工智能研究院副院长浙江省特级专家“这本书以明晰而简洁的文字，阐述了大语言模型的工作原理，堪称杰作。更为可贵的是，书中还详细介绍了ChatGPT的工程实施策略。”——金耀辉 上海交通大学人工智能研究院总工程师、教授“这是一本有关大语言模型应用和服务的实践指导书，详细介绍了如何开发基于大语言模型算法的应用和服务。这本书注重实际任务的设计及实现的思路讲解，并提供了对自然语言处理基础知识和算法原理的科普性介绍。”——张俊林 新浪微博新技术研发负责人三、给读者的学习建议第一，从第1章进行一个科普入门。书籍后面的内容根据内容规模和难度，讲解顺序重新排列为：相似匹配、句词分类、文本生成、复杂推理......读者可以按部就班地学习，也可以根据自己的兴趣选择任意章节进行学习。因为各章节相对独立，彼此没有直接明显的前后依赖关系，在学习时可以灵活调整。第二，以“任务”为核心。本书注重“任务”多于“工具”，虽然ChatGPT 是目前大语言模型领域总体效果最好的，但未来一定会有其他更好的大语言模型出现。书中详细介绍了与NLP相关的任务（如相似匹配、句词分类、文本生成、复杂推理）的背景和系统设计，这些方法也适用于其他大模型。只要读者理解了要做的事情，理解了系统设计，工具就能为我们所用。第三，利用好本书内容、提供的思维导图、GitHub开源项目HuggingLLM、B站视频课程等各种资源，来全方位地助力自己的学习与实践。· GitHub开源项目HuggingLLM链接：datawhalechina/hugging-llm：HuggingLLM, Hugging Future. (github.com)· B站视频课程链接：学会如何使用大模型，让创意有能力落地成应用：HuggingLLM，Hugging未来_哔哩哔哩_bilibili第四，一定要亲自动手完成一个应用或服务的 Demo！你可以在书中找到详细的示例代码，稍做修改后就可以在实际环境中使用。光看不做在编程领域是绝对行不通的，只是想想或者口头上说与亲自动手完全是两回事。万事开头难，但一旦完成了第一个项目，后面再做类似的就会相对容易一些。所以大胆地实操吧！另外要说明的是，这本书不是特别为算法或者自然语言处理工程师等行业人员设计的。当然，如果你是NLP工程师，也可以通过这本书受益。这本书更适合以下人员：· 对ChatGPT感兴趣的人；· 希望实际运用这项技术来创造新的服务或者解决现有问题的人；· 有一定编程基础的人。目前是首批发行，5 折优惠购买地址：https://u.jd.com/ficxj2dEND预览时标签不可点