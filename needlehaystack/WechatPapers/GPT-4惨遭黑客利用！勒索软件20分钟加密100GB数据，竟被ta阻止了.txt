GPT-4惨遭黑客利用！勒索软件20分钟加密100GB数据，竟被ta阻止了          原创                                      新智元                                                  新智元              新智元微信号AI_era功能介绍智能+中国主平台，致力于推动中国从互联网+迈向智能+新纪元。
重点关注人工智能、机器人等前沿领域发展，关注人机融合、人工智能和机器人革命对人类社会与文明进化的影响，领航中国新智能时代。
  新智元报道  编辑：编辑部【新智元导读】黑客已经用大模型把自己全面武装起来了！ChatGPT曾多次被黑客利用编写恶意代码、攻击网络，以获取个人信息。
在这个大模型并不安全的时代，国内一家同时深耕安全和AI的公司出手了。
没有人会怀疑，2024年是大模型落地应用元年，各行各业都在被大模型加速改造。
但是没想到，最先用大模型提升生产力的，居然是网络黑客！不久前，外媒报道，OpenAI和微软发现，黑客已经在不断地使用ChatGPT等大模型来完善和改进他们现有的网络攻击。
「Thallium」和「Curium」利用LLM研究公开报告的漏洞和目标组织，生成网络钓鱼邮件和代码。
「Forest Blizzard」组织使用GPT-4研究卫星通信和雷达成像技术。
「Emerald Sleet」组织利用GPT-4识别亚太地区防御问题专家和组织，探查公开漏洞，完成脚本任务，起草网络钓鱼邮件。
当然，OpenAI在检测出这些黑客账号之后就把他们都停了，但是在OpenAI关停相关账户之前，他们已经利用GPT-4进行了海量的攻击行为。
而且OpenAI也承认，他们没有办法完全提前阻止黑客将ChatGPT用于网络攻击活动。
另一方面，有黑客甚至已经在网上开始公开兜售使用GPT大模型和黑客数据专门训练出来的WormGPT和FraudGPT了！200刀一个月，任何人都可以用这个FraudGPT来生成钓鱼邮件，破解工具代码，大幅提升黑客的攻击效率。
包年的话还有折扣，只要1700刀。
按照这个黑帽版ChatGPT的宣传，普通人用自然语言就能输出各种钓鱼邮件和钓鱼短信，诱骗受害者将自己银行帐户交给攻击者。
不仅如此，FraudGPT还可以用来编写恶意代码，创建无法检测的恶意软件，查找不需要验证持卡人身份的银行识别号码，查找网站和系统的漏洞、薄弱点。
甚至只要你愿意花时间，它还能教你如何从零开始做一名合格的黑客。
显然，安全行业面对黑客在AI加持之下的全面升维攻击，如果还使用传统的方法来应对，就像是用冷兵器去对抗「核武器」。
如果安全行业不能利用大模型武装自己，在未来必将会被潮水一般的攻击行为所淹没。
360用安全大模型给出的答案，让全行业看到了未来「AI安全攻防战」的精彩之处。
在一家大型制造企业中：数十条生产线日均产生EB级数据量。
业务架构复杂，数据体系庞大，这类大型企业一旦中招勒索攻击，几乎无解。
有一天，安全分析人员突然收到了一封来自360本地安全大脑的AI高危告警。
360安全大模型智能化解读后发现，在两台名为v-wangshen/PC和luohao/PC的计算机上，短时间内发生了大量可疑的文档重命名操作。
涉及财务报表.XLS.lockbit和员工名单.XLS.lockbit等敏感文件。
LOCKBIT号称世界上加密最快的勒索软件。
据360云端安全大脑情报显示，该病毒20分钟即可完成100GB数据的加密。
这就意味着，如果不快速处置，2个小时后，将可能有一条生产线面临瘫痪。
千钧一发之际，360安全大模型赋能下的本地安全大脑立即推荐了一套AI智能化勒索告警处置预案。
自动提取：钓鱼邮件特征，可疑IP，威胁样本和漏洞信息，列入黑名单，封禁、查杀、隔离。
处置预案执行的同时，本次攻击背后的疑云也被360本地安全大脑一一解开。
360安全大模型智能化抽取全网探针信息发现，360 NDR AI探针曾上报：两台受害主机均收到过由某邮箱发来的工资单邮件。
结合360 EDR AI探针云端情报，360安全大模型智能化溯源，完整还原出了攻击链。
攻击者使用了CVE-2022-30190远程代码执行漏洞，诱导用户打开文档释放恶意代码。
Powershell.exe进程执行嵌入lockbit加密脚本。
最后通过智能化调查处置，发现目前仅有「win 10 P2021219」「win 10 PC」两个办公域资产受到影响。
无一条业务线中断。
在这个典型案例中，企业安全人员在大模型的加持下，迅速处理LOCKBIT勒索攻击，为企业挽回了不可估量的损失。
而背后360安全大模型，是国内首个将大模型应用于网络安全实战的成果，实现了对网络安全的全链路升级改造。
最近，360将去年发布的360安全大模型迭代到了3.0版本，为整个安全行业如何全面拥抱大模型技术打了个样。
360安全大模型3.0，开辟垂类大模型训练全新战法数据致胜在大模型落地应用过程中，各行各业的专有数据是产生价值的关键，这几乎已经成为了共识。
360安全大模型3.0的数据优势，主要体现在两个方面：1. 360拥有海量的安全语料精度更高，质量更高，训出来的大模型水平也会更高。
高质量的安全语料需要广泛的数据来源和长期的积累。
这是360近20年来积累的核心资产。
2. 360有很多专业数据，比如拥有海量的EDR、NDR事件数据。
而且这些数据并不那么容易训练，需要清洗语料，特别是要调整结构、修改推理环节等比较底层的技术才能真正体现出这些专业数据的价值。
所以简单来说，安全行业的数据采集和训练都是有很高门槛的。
而360在安全行业多年的深耕，无疑是最有可能把数据问题解决好的企业，从而奠定了360安全大模型的能力基础。
小切口，大纵深有了数据带来的基础优势，如何把AI能力分解在安全行业业务场景之中，能否在安全行业用好大模型的另一个关键问题。
360提出的「小切口，大纵深」，希望从安全行业难点的小场景做切入，做深做透，深度融合安全能力。
小切口的意思是将一个复杂的任务场景分解成很多小场景，其中有一部分是过去的方法能解决的。
而大模型，应该去聚焦解决那些传统方法无法解决的难题部分。
把一个个小场景都逐一解决了，合在一起就能达成更大更复杂的任务目标。
比如对于「自动化安全运营」这个大目标，拆成数十个小任务，有些任务可能以前的工具能完成，有些任务引入大模型之后就能自动化完成。
最终每个点都打通之后，就能实现整个安全运营过程或者某些场景下自动运营。
例如像开头案例中那样，安全大模型对恶意邮件进行自动检测，自动分析行为日志等多项自动化流程，让安全人员及时处理攻击，并且自动分析攻击链条，完成安全漏洞和弱点的排查。
大纵深，就是在小切口基础上做深做透，深度融合大模型和安全的能力。
大纵深也包括了两个含义：一是模型本身专业领域的深入，安全领域了解要非常透彻，获取这个领域真正的专家知识。
比如MITRE的ATT&CK。
360有远远超过它的技战术，能把将近20年积累起来的最顶尖的领域知识运用到行业大模型中。
二是必须将获得的知识和数据进行深度融合，不是搜罗一些私有数据后简单地微调一下，或者放到现在的数据库里做RAG，就能实现深度融合。
因为这样的做法本质上只是多了私有知识的通用大模型，走的还是通用大模型简单应用的路，体现不出对于客户更深的专业价值。
类脑分区协同CoE真正将大模型的能力在安全领域落地，360安全大模型3.0核心变化最主要体现在「类脑分区协同（CoE）」的独特构架上。
360安全大模型3.0打造的类脑能力体系，能够调动各功能中枢协同工作，共同支撑安全大模型实现专家级安全能力。
这本质上是参考大脑的功能，因为人类大脑的功能是分区的，而且这些多功能区是协同工作的。
360借鉴大脑的功能分区结构，搭建了类脑分区协同的CoE框架，作为360安全大模型的核心框架。
而这么设计结构框架，一方面是要解决模型训练过程中实际遇到的问题。
因为在训练模型时可以经常感受到，任务之间是有冲突的。
比如训练本脑HQL这样的结构化语句，可能就和漏洞相关的训练有所冲突，一边学好了另一边的能力会下降。
所以用不同的中枢将模型进行区隔，将有效降低这种冲突产生的可能，保证各个能力点都全力发挥。
而另一方面，CoE名字虽然借鉴「混合专家模型」：MoE，但是在实际的运转过程中又有自己独特的特点。
与MoE在工作时会同时激活几个专家模型不同，CoE重点在于它的推理程序会在按阶段激活不同的专家，也就是按当时工作进展来激活不同的专家。
比如恶意邮件的研判，推理程序会首先推到研判专家的分区，研判专家会得出一个结果，推理程序再把它交由语言专家分区，最后再交给最终给用户的研判分析结果。
具体来说，类脑结构由以下5个中枢构成：1. 语言中枢，实现了像语言翻译、文本摘要、意图识别等能力。
语言中枢可以理解和应用Quake语言，HQL语言。
意图理解、报告生成、指令生成，这些场景都是在语言中枢中完成。
比如Quake语言中枢可以帮助安全大模型理解Quake查询规则、资产信息、提取信息摘要等等，还可以把用户的自然语言按照要求转化成结构化的查询语句。
2. 规划中枢就是实现程序生成、方案规划、目标拆解能力。
这些高级能力可以在很多复杂的任务中体现出来，比如：告警降噪、告警响应，威胁猎杀和攻击溯源等场景当中。
规划中枢会参与规划猎杀过程中任务的每个步骤，引导安全大模型和框架其他部分完成具体的操作。
3. 判别中枢实现了数据抽取、逻辑推理、是非判断，特定的研判检测。
它的能力主要是应用在恶意文件的判别，恶意邮件的判别，EDR的告警判别，攻击流量判别以及代码漏洞判别等任务场景中。
4. 道德中枢是实现内容安全的核心，保证了输出内容的无害性。
5. 记忆中枢，可以提供相应的记忆信息。
比如应用在知识问答场景，它可以和外部智能体当中RAG的方式配合使用。
以智能体框架为基础的工具增强——TAG而在安全大模型的大脑核心框架之外，还有一个用智能体搭建的能力增强系统。
类比于认知科学中认为人的思维过程分为下意识的「快思考」和集中注意力的「慢思考」过程。
大模型就像人类的「快思考」一样，通常会直接根据以前学习到的知识，快速得出一个结果，很容易产生「幻觉」。
对此，360以安全大模型为「大脑」，构建了一个智能体框架。
智能体框架具备了任务编排、指令调度、记忆存储能力，可以调用安全知识、工具，充分发挥RAG、TAG的能力。
这就相当于模仿了人类「慢思考」的过程，对安全大模型的结果进行纠错和能力增强，实现更强大的专家能力。
工具增强（TAG）是以安全智能体为基础，通过调动各种安全工具为安全模型提供了解外部世界的能力。
类似于检索增强RAG，所谓的工具增强，就是工具对模型的帮助其实远远超过检索这个层面。
特别是安全行业当中各种安全工具和产品，和大模型是能相辅相成的，不仅是能接受大模型的一些帮助，反过来它的数据能提升模型的效果。
TAG不单单是为大模型提供了外挂知识库，而是为大模型提供了手和脚，能够完成任务，还能像手和脚的触感一样在完成任务的过程中获取更多的数据，增强大脑的能力。
借用智能体框架再把大模型工作过程拉长，充分利用RAG、TAG的各种能力，可以给它提供纠错机制。
比如，在用户提问之前，安全大模型就可以先用工具，先用检索为它提供和任务相关的知识，在它回答问题之后，系统也可以用知识图谱对结果进行校验。
场景实战来看看围绕安全行业高难度、高价值的APT场景，360安全大模型是如何工作的。
360安全大模型智能化猎杀海莲花APT攻击第一步，威胁猎杀/威胁狩猎。
人类专家会从一个假设或猜测开始，触发一个主动网络防御的猎杀过程。
安全大模型也会模仿这个过程，利用智能体，通过外部的安全产品，发现APT的告警或事件。
比如这里就是修改系统，多项配置的事件。
在这个点，安全大模型就会触发它的猎杀任务。
第二步，任务生成。
智能体框架会生成猎杀任务，调度编排给安全大模型，在关键步骤通过TAG工具增强来增强大模型的能力。
第三步，规划编排。
安全大模型预演中枢是负责语言理解和意图理解。
理解之后，会由规划中枢来规划实现的方案，拆解行动的目标。
这个步骤也会利用智能体中预置的专家编排剧本来进行指导。
360安全大模型本身有大量的预置剧本可以提供很好的指导。
而且随着模型能力的不断提升，规划出来的实现方案效果会越来越好。
第四步，逆向追踪溯源。
在安全大模型规划了任务之后，判别中枢非常重要，它会抽取EDR、NDR日志。
这些日志信息会通过智能体调度辅助工具进行追踪溯源，找到攻击的源头。
第五步，正向梳理还原攻击链。
从源头梳理还原整个攻击链，过程对关联事件进行研判分析、固定证据、输出中间结果。
然后通过智能体安全攻防结果做消除「幻觉」的一些工作。
第六步，APT画像。
安全大模型通过攻击链以及过程中固定证据这些行为训练，判定攻击类型，判定APT组织，最后形成APT画像。
第七步，输出结果的内容检测。
记忆中枢支撑了每一步的信息记忆。
大模型安全问题，如何解安全，是大模型时代最大的挑战。
众所周知，大模型本身就是数字化系统，只要有数字化系统就存在安全问题，而且更加严重。
不过就这一层面来说，传统的网络与数据安全问题，可以部分地使用传统的安全方法解决。
但是，解决这一问题的根源在于大模型本身——大模型自身并不安全。
大模型背后的逻辑是概率token的预测，并非真正的理解，因此，LLM往往会产生「幻觉」输出不合规、暴力有毒的内容。
对于这些安全问题，需要创新手段去解决。
一种可能的方法是，对大模型进行深入了解，这也是OpenAI、Anthropic等大模型公司都在攻克的难点。
比如，去年OpenAI超级对齐团队发布了一篇关于用「GPT-2监督GPT-4」的论文，来解决人类面对比自己更聪明的AI时所面临的风险。
其次就需要「安全的大模型」出场。
因为对于那些不做LLM的企业来说，无法在大模型内部深入耦合原生安全机制，很难从根本上解决原生的大模型安全问题。
还有一种可能是，LLM整个链条不可控，因为大模型需要「多步调度」完成任务。
比如，让大模型把大象关进冰箱需要多少步？第一步把冰箱打开；第二把大象塞进去；第三把门关上，整个流程串起来构成一个完整的工作链条。
有没有想过，如果其中某一步被控制，LLM输出的结果就会失控，就会造成不可逆的影响。
当然，除了大模型自身问题，还有来自外部的原因——即大模型容易被攻破，恶意使用。
目前，许多学术界的研究就证明了GPT-4、PaLM等大模型所存在的严重缺陷。
比如，南洋理工提出的「越狱」新方法MasterKey让GPT-4、Bard等大模型集体失控，越狱成功率从平均7.3%直接暴涨至21.5%。
还有谷歌DeepMind提出的新方法只要不到20美元，可以从ChatGPT或PaLM-2等黑盒语言模型中窃取模型信息。
甚至包括，去年11月，ChatGPT大规模宕机事件，被爆出原因可能与DDoS攻击有关。
再往长远看，终极AGI到来那天，大模型控制人类愈加危险。
这也是为什么图灵巨头Hinton等人一直呼吁加强大模型安全的问题，防止终极末日的来临。
面对这些安全问题，360也给出了自己的思考。
大模型的安全问题若想得以解决，就需要攻克四大安全主题上的核心问题——可靠性、可信、向善、可控。
要知道，LLM安全体系架构是「双轮驱动」的，第一个轮子是传统的网络数据安全，第二个轮子是以内容为核心的原生安全。
因此，解决大模型可靠性，需要双轮。
而非业界侧重的仅仅保护网络与数据安全，构建安全的运营环境。
360认为，大模型内容的输入输出，就是大模型安全的核心。
正是基于这种以「内容」为主的防御思路，360提出了「安全原生」的基本原则，通过「以模制模」的策略，即以小模型技术保障大模型的安全。
与此同时，360也提出了大模型的体系框架——AISF，大模型内部嵌入对内容的管控，对行为的管控，对知识的增强这三套措施。
这便是，360大模型具体安全解决方案——「双轮框架模型」。
基于自身提出的策略，360在大模型安全领域做出了诸多的落地成果。
安全大模型行业领头人，360凭什么？前段时间，赛迪顾问发布的《中国安全大模型技术与应用研究报告（2023）》中，「360安全大模型」凭借突出的技术能力和业务布局，位居图表首位，综合实力领先行业。
360背后凭借什么，能够成为行业安全大模型领头人？一来，360也是国内最早迈入大模型领域的互联网企业之一，自主研发的千亿参数「360智脑大模型」，成为行业模型的基础底座。
再者，自创立至今，360在AI安全应用和安全数据方面，已经拥有近20年经验积累，为训练安全大模型提供了丰富的「养料」。
具体来说，360是在国内最早实现AI在网络安全领域应用化的公司，从诞生起便自带「安全」基因。
2010年，360自主研发了世界首个采用AI技术的反病毒引擎360 QVM，具备「自学习自进化」的能力。
它在国际评测机构AV-TEST全球杀软评测中夺冠，也创造了亚洲杀软的历史纪录。
随后相继在14、17年发布了下一代QVM，以及QAPT人工智能高级威胁检测引擎，不断加深技术积累完成迭代，与此同时，作为领先的科技公司，360也是国内为数不多的长期深耕AI的厂商，在AI领域不断持续投入。
2015年，AI研究院成立。
2018年，360团队开启了多模态CV领域的研究，并取得了许多技术成果。
值得一提的是，在人工智能世界杯当中，360还战胜了图灵奖团队，拔得头筹。
去年，千亿级参数规模的「360智脑」大模型发布，具备了生成创作、多轮对话、逻辑推理等十大核心能力。
到目前为止，已经迭代了4个版本，在行业中得到了实际应用。
可见，360自身在多模态、跨模态技术应用以及NLP大模型核心技术中，有了强大的技术积累。
此外，作为全球首个大模型安全风险评估首创者，360也承接了「安全大脑」——国家级人工智能开放平台项目，能够为安全大模型的赋能。
去年8月，360「安全大模型1.0」首次诞生之后，侧重的是智控系统，一经发布就有了300+个API接入。
随后升级的2.0版本，将不同场景细分之后，通过智能体完成一些自动化的工作。
与此同时，「小切口、大纵深」的理念已经形成。
不过，2.0阶段大模型，在客户的实际应用中，仍旧面临一些挑战。
因此，360团队继续深耕安全大模型本身的能力，从模型结构、推理等逐渐深入，也就是我们现在看到的3.0版本。
此外，360安全云在安全大模型加持下，形成公有云和私有化两大场景。
在公有云场景下，打造安全云服务，充分利用AI提升运营效率；在私有化场景下，深度优化安全大脑+安全大模型+探针的能力落地。
最重要的是，安全大模型实实在在地带来了极大的生产力提升：高效看见告警的解读、任务的编排、分析溯源等；可以筛选出更精准的告警，发现隐蔽性比较强的，工作人员发现不了的告警；自动化处置，无需人们通过通讯工具处理；提供更多的用户体验，以往安全运营人员需要鼠标在菜单页面繁琐操作，而现在只需要语音问答，大模型即可完成。
360首席科学家兼360数字安全集团CTO潘剑锋表示，360安全大模型还会进一步迭代升级，而下一步规划主要分为两个部分，一是扩充场景，二是不断深耕模型。
进一步愿景是，360安全大模型可以直接应用到垂直模型之上，扩充更多的场景。
其次，模型能力高低与「基座模型」有着直接的关系，360也将不断深耕安全大模型，同时向通用模型的一些通用能力发力。
360安全大模型3.0的发布，正式开启了智能化安全运营的时代！预览时标签不可点