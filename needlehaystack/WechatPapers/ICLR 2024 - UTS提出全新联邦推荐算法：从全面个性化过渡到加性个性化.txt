​ICLR 2024 | UTS提出全新联邦推荐算法：从全面个性化过渡到加性个性化          原创                                      李志伟                                                  PaperWeekly              PaperWeekly微信号paperweekly功能介绍PaperWeekly是一个推荐、解读、讨论和报道人工智能前沿论文成果的学术平台，致力于让国内外优秀科研工作得到更为广泛的传播和认可。社区：http://paperweek.ly | 微博：@PaperWeekly©PaperWeekly 原创 · 作者 | 李志伟单位 | 悉尼科技大学博士生研究方向 | 联邦推荐算法这篇论文提出了一种新的联邦推荐算法 FedRAP。FedRAP 在联邦学习框架中同时针对用户信息和项目信息实施双边个性化策略，以此来增强推荐系统在隐私保护和个性化推荐方面的表现。它通过逐步提高正则化权重，平滑地从全面个性化过渡到加性个性化。同时，FedRAP 还引入了对全局项目嵌入进行稀疏化处理的策略，有效降低了通信开销。论文标题：Federated Recommendation with Additive Personalization论文链接：https://arxiv.org/abs/2301.09109代码链接：https://github.com/mtics/FedRAP随着对隐私保护需求的增加，联邦学习环境下推荐系统的开发成为了构建下一代互联网服务架构的新趋势。但是，现有方法多是基于分布式推荐框架并附加隐私保护机制演化而来，这使得它们在联邦推荐系统中很难充分发挥个性化的潜力。为了解决这一问题，本文提出了一种创新方法——联邦推荐与加性个性化（FedRAP），该方法通过分析用户偏好和其对项目的个人理解来优化推荐效果。FedRAP 的核心在于加性个性化技术，它通过将个性化的项目嵌入与所有用户共同形成的稀疏全局项目嵌入相结合。此外，为了缓解不同客户端间项目嵌入的差异性可能导致的性能问题，FedRAP 采用了逐步增加正则化权重的策略，并通过全局项目嵌入的稀疏化处理来减少通信负担。在四个现实世界的推荐数据集上进行的实验验证了 FedRAP 方法的有效性。背景和动机近年来，推荐系统已经成为一个重要的工具，它能够向用户推荐他们可能感兴趣的新内容，并且显著地影响了我们的日常生活。这些系统一般都依赖中心服务器来收集并整合用户的数据、活动记录和偏好信息，以此来训练出能够做出精准推荐的模型。然而，用户数据往往含有敏感的隐私信息，一旦上传至服务器就可能面临严重的隐私和安全风险。近期，一些隐私保护法规（例如 GDPR）更是明确要求用户数据应当存储于本地设备，而非上传至云端服务器。针对上述问题，联邦学习（FL）提供了一个潜在的解决方案。它通过在客户端进行本地模型训练，并将训练后的本地模型在服务器端进行聚合，实现了数据的本地化和分布式全局模型训练。FL 已在多个应用场景中取得显著成效，比如谷歌键盘的查询建议功能。然而，客户端之间的数据异质性可能会大幅延缓 FL 的收敛速度，导致客户端漂移或者个别客户端的全局模型性能下降。为了在保护用户隐私的同时促进不同客户端间的知识共享，学者们正在积极研究联邦推荐系统（FRS）。FRS 能够处理单个用户的客户端数据，以此来构建用户的个人资料。在此情境下，用户的资料和评分数据应当被保留在本地客户端，而服务器则负责存储项目信息。联邦推荐系统在保护用户隐私的同时，还需要在通信成本和模型精度之间找到一个恰当的平衡点，以便提供最优化的推荐结果。然而，现有的方法往往忽略了用户对相同项目的感知不同的问题，即：不同用户可能对同一项目有不同的偏好，并关注于项目的不同特性。为了解决现有联邦推荐系统中的这些问题，本文提出了一种名为联邦推荐与加性个性化（FedRAP）的新算法。FedRAP 通过将加性个性化技术应用于项目嵌入，并通过使全局项目嵌入变得稀疏来减少通信成本和延迟。此外，FedRAP 还采用了一种逐渐变化的参数调整方法，以平衡全局知识共享和本地个性化之间的权衡。FedRAP 遵循水平联邦学习的假设，即：不同客户端拥有独特的用户和数据集，但共享相同的项目。具体而言，FedRAP 的主要贡献包括：1. 双边个性化：FedRAP 为每个客户端提供了私有的用户嵌入，同时通过将与用户相关的本地项目嵌入与在服务器上聚合更新的全局项目嵌入相加，实现了项目的加性个性化。2. 双重正则化策略：一方面 FedRAP 鼓励稀疏性以减少通信开销，另一方面 FedRAP 确保本地和全局项目信息的多样性以保证其互补性。3. 逐渐变化的正则化权重：为了应对早期训练中加性个性化可能带来的性能损失，FedRAP 采取逐步增加正则化权重的方法，来将完全个性化逐渐过渡到加性个性化。因此，FedRAP 能够利用客户端本地存储的部分评分数据，预测用户对未评分项目的评分，同时兼顾项目的全局视角和用户特定视角。在六个真实数据集上的实验结果表明，FedRAP 在联邦推荐领域显著优于现有方法。联邦推荐与加性个性化（FedRAP）为了便于理解和阐述，我们在此不展开讨论具体的公式细节，更多深入的内容请参阅原始论文。FedRAP 用  表示第  个用户的个性化特征，这些特征是根据用户的历史数据学习得到的，用于捕捉用户的偏好和行为。为了在保持用户之间共享项目信息的同时实现项目个性化，FedRAP 定义  来表示服务器上聚合的项目嵌入，这包含了所有用户共有的项目信息。并且 FedRAP 定义  来捕获对于第  个用户有意义的项目信息FedRAP 的主要思路是：在联邦学习框架中，通过加性个性化技术结合全局项目嵌入（）与用户特定的本地项目嵌入（），实现既保护用户隐私又提供个性化推荐的推荐系统。除此之外，FedRAP 还应能够尽可能地减少通讯开销，即减少  中的参数量。因此，FedRAP 具有如下所示的框架图。具体来讲，FedRAP采用以下策略：加性个性化：首先，算法通过将每个用户的本地项目嵌入 (  ) 与全局项目嵌入 (  ) 相加的方式来实现个性化。这种加性方法使得每个用户的推荐不仅受到其个人偏好的影响，同时也融入了全局的项目趋势和特征。正则化约束：为了确保  和  学习到的内容具有差异性，FedRAP 的目标函数中加入了一个正则化项。这一项的作用是最大化  和  之间的 Frobenius 范数，即 ，其中  是客户端的数量。这种设计强制每个  学习用户特定的信息，而  则保留更普适的、对所有用户都有用的信息。稀疏正则化：为了进一步鼓励  仅学习对推荐最有用的信息，FedRAP 将  的稀疏性作为正则化目标，并通过  范数进行约束。这样不仅可以减少模型在通信时的开销，还可以使  专注于那些对多数用户都重要的特征。逐渐变化的正则化权重：此外，为了在训练的早期阶段减轻加性个性化可能带来的性能下降，FedRAP 在训练初始时，会使用较小的正则化权重以允许模型集中学习用户和项目的基本特征；而随着训练的进行，FedRAP 会逐步增加权重以引导模型更多地关注个性化特征，以此平衡全局信息和个性化需求，促进模型的稳定收敛和提高推荐准确性。综上所述，通过这样的目标函数设计，FedRAP 能够有效地使全局项目嵌入  学习到对所有用户普遍有用的项目特征，同时使每个用户的本地项目嵌入  学习到用户特有的个性化信息。这种方法允许 FedRAP 在确保推荐系统准确性的同时，兼顾到个性化需求和全局信息的整合。实验数据集：为了评估 FedRAP 的性能，本文在六个热门的推荐系统数据集上进行了全面的实验研究，这些数据集分别是：MovieLens-100K（简称 ML-100K）、MovieLens-1M（简称 ML-1M）、Amazon-Instant-Video（简称 Video）、LastFM-2K（简称 LastFM）、Ta Feng Grocery（简称 TaFeng）和 QB-article。前四个数据集中包括的评分范围是 1-5。鉴于本文的研究目标是对包含隐式反馈的数据进行推荐预测，本文将这些数据集中所有大于 0 的评分均设定为 1。而 TaFeng 和 QB-article 两个数据集包含了基于用户交互日志的隐式反馈信息。在每个数据集中，我们仅考虑了那些至少对 10 个项目做出评价的用户。基线：本文通过与中心化和联邦学习设置中几种先进方法的对比来验证 FedRAP 的有效性，这包括 NCF、LightGCN、FedMF、FedNCF 和 PFedRec。具体的实验细节，请参考原始论文。评价指标：本研究采用了命中率（HR@K）和归一化折扣累积增益（NDCG@K）作为评价指标，并将 K 设置为 10。所有的实验都进行了五次重复，以确保结果的可靠性，并报告了实验结果的平均值及其标准偏差。3.1 主要结果上图的实验结果显示，在使用的六个数据集中，FedRAP 在绝大多数情况下都超过了其他方法，且在所有联邦学习方法中表现最为突出。这种卓越表现可能归因于 FedRAP 在用户和项目信息上执行的双边个性化策略。相比于 PFedRec，FedRAP 之所以展现更好的性能，是因为它在个性化项目信息的同时，能够有效保留项目的共性信息，避免了潜在的信息丢失。而 CentRAP 在所有数据集中的表现略胜 FedRAP 一筹显示了 FedRAP 在所采用的数据集中潜在的性能上限。此外，我们还研究了 FedRAP 的收敛速度，通过比较 ML-100K 数据集上各方法（除了 CentRAP 外）在训练过程中每次迭代的表现。下图的结果展示了 FedRAP 的性能优势，但同时也指出，由于 FedRAP 的复杂性高于 PFedRec，其达到收敛状态需要更多的迭代次数。3.2 项目信息的可视化论文还通过可视化的方式展示了 FedRAP 在个性化项目信息方面的优势。文中研究了全局项目嵌入 (  ) 与本地项目嵌入 (  ) 在 FedRAP 中的作用。为了将其可视化，论文从 ML-100K 数据集上学习到的模型中，选取了三个本地项目嵌入 ( 、 和  )，以及全局项目嵌入 (  )。由于研究主要集中在隐式反馈推荐上，也就是项目被用户评分或未评分，本文通过 t-SNE 方法将这些项目嵌入映射到二维空间中，并在图中展示了归一化的结果，其中紫色代表用户未评分的项目，红色代表用户已评分的项目。从上图可以看出，用户评分和未评分的项目在  中混杂在一起，这说明  只保留了用户间共有的项目信息。而  学习到的项目信息可以明显地为第  个用户划分成两个类别，这表明  只学习与第  个用户相关的项目信息，例如用户对项目的偏好。此外，文中还将  和  相加以展示第  个用户的项目信息的加性个性化，这在图中也有所显示。这些图再次证实了 FedRAP 有效实现项目信息个性化的能力。更多实验结果请见原论文。结论本文提出了一种名为 FedRAP 的方法，通过同时实现用户信息个性化和项目信息的加性个性化，做出了双边个性化的联邦推荐。FedRAP 通过逐渐增加正则化权重，实现了从完全个性化到项目信息加性个性化的课程，以减轻在训练早期使用加性个性化引起的性能下降。此外，通过对全局项目嵌入施加稀疏性约束来移除无用的推荐信息，这也有助于减少通信成本。由于客户端在每次迭代中只上传更新的全局项目嵌入到服务器，因此 FedRAP 避免了用户信息的泄露。通过在 6 个广泛使用的真实世界推荐数据集上进行的比较实验和大量的消融研究，FedRAP 证明了其有效性。此外，由于 FedRAP 的简单性，探索其在其他联邦场景中的应用将是有趣的。作者简介李志伟第一作者，目前在悉尼科技大学攻读博士学位，跟随导师龙国栋教授从事联邦推荐算法的研究。个人主页：https://zhw.li/龙国栋悉尼科技大学副教授，组里正在招收博士生一起探索联邦学习及其应用。个人主页：https://profiles.uts.edu.au/guodong.long周天翼马里兰大学帕克分校助理教授个人主页：https://tianyizhou.github.io/更多阅读#投 稿 通 道# 让你的文字被更多人看到 如何才能让更多的优质内容以更短路径到达读者群体，缩短读者寻找优质内容的成本呢？答案就是：你不认识的人。总有一些你不认识的人，知道你想知道的东西。PaperWeekly 或许可以成为一座桥梁，促使不同背景、不同方向的学者和学术灵感相互碰撞，迸发出更多的可能性。 PaperWeekly 鼓励高校实验室或个人，在我们的平台上分享各类优质内容，可以是最新论文解读，也可以是学术热点剖析、科研心得或竞赛经验讲解等。我们的目的只有一个，让知识真正流动起来。📝 稿件基本要求：• 文章确系个人原创作品，未曾在公开渠道发表，如为其他平台已发表或待发表的文章，请明确标注 • 稿件建议以 markdown 格式撰写，文中配图以附件形式发送，要求图片清晰，无版权问题• PaperWeekly 尊重原作者署名权，并将为每篇被采纳的原创首发稿件，提供业内具有竞争力稿酬，具体依据文章阅读量和文章质量阶梯制结算📬 投稿通道：• 投稿邮箱：hr@paperweekly.site • 来稿请备注即时联系方式（微信），以便我们在稿件选用的第一时间联系作者• 您也可以直接添加小编微信（pwbot02）快速投稿，备注：姓名-投稿△长按添加PaperWeekly小编🔍现在，在「知乎」也能找到我们了进入知乎首页搜索「PaperWeekly」点击「关注」订阅我们的专栏吧···预览时标签不可点