离职谷歌的Transformer作者创业，连发3个模型（附技术报告）                          机器之心              机器之心微信号almosthuman2014功能介绍专业的人工智能媒体和产业服务平台机器之心报道编辑：陈萍、小舟去年 8 月，两位著名的前谷歌研究人员 David Ha、Llion Jones 宣布创立一家人工智能公司 Sakana AI，总部位于日本东京。
其中，Llion Jones 是谷歌 2017 年经典研究论文《Attention is all you need》的第五作者，该论文提出了深度学习架构 transformer。
transformer 对整个机器学习领域产生了重要影响，并且是 ChatGPT 等生成式 AI 模型的基础。
论文于 2017 年 6 月首次发表后，随着全球对生成人工智能人才竞争不断升温，论文作者陆续离开谷歌，自立门户创业。
Llion Jones 是八位作者中最后一个退出谷歌的人。
David Ha、Llion Jones 成立的初创公司 Sakana AI 致力于构建生成式 AI 模型。
最近，Sakana AI 宣布推出一种通用方法 ——Evolutionary Model Merge。
该方法使用进化算法来有效地发现组合不同开源模型的最佳方法，这些开源模型具有不同功能。
Evolutionary Model Merge 方法能够自动创建具有用户指定功能的新基础模型。
为了测试其方法的有效性，研究团队用 Evolutionary Model Merge 方法演化出能够进行数学推理的日语大语言模型（LLM）和日语视觉语言模型（VLM）。
实验结果表明这两个模型在没有经过明确优化的情况下，在多个 LLM 和视觉基准上都取得了 SOTA 结果。
特别是，其中进行数学推理的日语 LLM 是一个 7B 参数模型，它在大量日语 LLM 基准上取得了顶级性能，甚至超过了一些 SOTA 70B 参数 LLM。
最终，研究团队应用 Evolutionary Model Merge 方法演化出 3 个强大的基础模型：1. 大语言模型（EvoLLM-JP）2. 视觉语言模型（EvoVLM-JP）3. 图像生成模型（EvoSDXL-JP）值得注意的是，Evolutionary Model Merge 方法能够自动生成新的基础模型，而不需要任何基于梯度的训练，因此需要相对较少的计算资源。
Sakana AI 团队认为：受自然选择启发的进化算法可以解锁有效的开源方法合并解决方案，以探索广阔的可能性空间，发现传统方法和人类直觉可能错过的新颖且不直观的组合。
技术详解技术报告介绍了 Evolutionary Model Merge 这种通用进化方法。
报告地址：https://arxiv.org/pdf/2403.13187.pdf本文的目标是创建一个统一的框架，能够从选定的基础模型中自动生成合并模型，以确保该合并模型的性能超过集合中任何个体的性能，方法的核心是进化算法。
研究者首先将合并过程剖析成两个不同的、正交的配置空间，并分析它们各自的影响。
基于此分析，他们随后引入了一个无缝集成这些空间的内聚框架。
图 1 为示意图。
Evolutionary Model Merge 结合了：（1）合并数据流空间（Data Flow Space）中的模型，以及（2）合并参数空间（权重）中的模型。
数据流空间：是通过进化来发现不同模型各层的最佳组合以形成新模型。
下面是这种方法的一个示例：参数空间：第二种方法是开发混合多个模型权重的新方法，混合不同模型的权重以形成新的模型。
下面视频为两种不同模型混合权重的过程说明：数据流空间和参数空间这两种方法也可以结合在一起来开发新的基础模型：该研究希望通过进化的方法来帮助找到更好的模型合并方法，通过实验，研究者证明了该方法能够创建具有以前不存在的、新的、具有新兴组合功能的新模型。
实验中，研究者使用这种自动化方法生成了两个新模型：一个日语数学 LLM 和一个支持日语的 VLM，它们都是使用这种方法演化而来的。
具有 SOTA 性能的基础模型该研究提出了三种模型：大型语言模型（EvoLLM-JP）、视觉语言模型（EvoVLM-JP）以及图像生成模型（EvoSDXL-JP）。
EvoLLM-JPEvoLLM-JP 是一个可以用日语解决数学问题的 LLM。
为了构建这样的模型，该研究使用进化算法来合并日语 LLM（Shisa-Gamma）和特定于数学的 LLM（WizardMath 和 Abel）。
实验过程中，研究者允许模型不断的进化迭代，最终模型采用的是在 100-150 次的进化中表现最好的模型。
研究者在 MGSM 数据集上进行了评估，以下是评估结果：该表格比较了不同 LLM 用日语解决数学问题的表现，MGSM-JA 列显示正确答案的百分比。
模型 1-3 为原始模型，模型 4-6 为优化后的合并模型。
模型 7-10 是用于比较的 LLM 得分。
上表为进化后的 LLM 结果。
其中模型 4 在参数空间中进行了优化，模型 6 使用模型 4 在数据流空间中进行了进一步优化。
这些模型的正确响应率明显高于三个源模型的正确响应率。
不过研究者表示根据以往的经验，手动将日语 LLM 与数学 LLM 结合起来非常困难。
但经过迭代努力，进化算法能够有效地找到一种将日语 LLM 与数学 LLM 结合起来的方法，成功地构建了一个兼具日语和数学能力的模型。
除了数学能力外，研究者还评估了模型的日语能力。
令人惊讶的是，该研究发现这些模型在一些与数学无关的任务上也取得了高分。
值得注意的是，模型并没有经过特定优化，但实际效果还不错。
LLM 日语整体能力比较，其中 Avg 栏是 9 个任务得分的平均值，数值越高，代表 LLM 日语整体能力越高。
EvoVLM-JP该研究发现，进化算法还可以进化成不同架构的模型。
他们通过应用进化模型合并生成了一个日语视觉语言模型 (VLM)。
在构建日语 VLM 时，该研究使用了流行的开源 VLM (LLaVa-1.6-Mistral-7B) 和功能强大的日语 LLM (Shisa Gamma 7B v1)。
研究者表示，这是合并 VLM 和 LLM 的第一次努力，其证明了进化算法可以在合并模型中发挥重要作用。
以下是评估结果。
VLM 性能比较。
上表中，JA-VG-VQA-500 和 JA-VLM-Bench-In-the-Wild 都是关于图像问答的基准。
分数越高，表示用日语回答的答案越准确。
以下为模型在回答有关图像问题的示例展示。
两种基线模型经常给出错误的答案，而 EvoVLM-JP 给出正确的答案。
例如用户询问交通信号灯现在是什么颜色时，通常来讲，正确答案是绿色，但是在日语习惯中，都会说成蓝色。
可以看出 EvoVLM-JP 比较贴合日语习惯。
‍EvoSDXL-JP该研究发现，进化也可以自动发现合并不同扩散模型的方法。
EvoSDXL-JP 根据提示生成图片。
参考链接：https://sakana.ai/evolutionary-model-merge/© THE END 转载请联系本公众号获得授权投稿或寻求报道：content@jiqizhixin.com预览时标签不可点