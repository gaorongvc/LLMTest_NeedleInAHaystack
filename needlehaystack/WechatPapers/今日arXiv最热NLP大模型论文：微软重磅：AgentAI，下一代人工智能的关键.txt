今日arXiv最热NLP大模型论文：微软重磅：AgentAI，下一代人工智能的关键          原创                                      Tscom                                                  夕小瑶科技说              夕小瑶科技说微信号xixiaoyaoQAQ功能介绍更快的AI前沿，更深的行业洞见。
聚集25万AI一线开发者、互联网中高管和机构投资人。
一线作者来自清北、国内外顶级AI实验室和大厂，兼备行业嗅觉与报道深度。
夕小瑶科技说 原创作者 | Tscom引言：AI的全面智能之路人工智能的发展已从简单算法进化到复杂的大型基础模型，尤其在理解开放世界环境中的感官信息方面取得显著进步。
然而，关键转折点在于从过度简化方法转向强调整体运作的系统，催生了Agent AI的兴起。
Agent AI将大型基础模型整合到代理行动中的具体系统，涉及机器人学、游戏和医疗保健等多领域。
本文提出新的代理基础模型，展现其在多个任务和领域中的非凡能力，挑战传统学习和认知观念。
同时，从跨学科角度探讨Agent AI潜力，强调AI认知和意识的重要性。
这些讨论为未来研究奠定基础，促进社会广泛参与。
本文深入探讨了Agent AI的基础，强调了智能代理在物理、虚拟或混合现实环境中，根据感官输入自主执行情境相关行动的能力。
这种新范式突出了具身智能的重要性，强调整合复杂动态交互代理方法的必要性。
我们坚信，智能源于学习、记忆、行动、感知、规划和认知间的复杂互动。
Agent AI框架（下图）的构建将促进AI社区对从被动、结构化任务模型向复杂环境中动态交互角色模型的转变所需见解和知识的积累。
这是迈向人工通用智能（AGI）的关键一步。
论文标题: Position Paper: Agent AI Towards a Holistic Intelligence论文链接: https://arxiv.org/pdf/2403.00833.pdfAgent AI的定义与重要性1. Agent AI的概念和目标Agent AI，或称为代理人工智能，是一种智能体，能够基于感官输入自主执行适当且与上下文相关的行动，无论是在物理、虚拟还是混合现实环境中。
Agent AI代表了一种新的范式，强调了整合智能体在复杂动态中的互动方式的重要性。
这种方法的动力来自于认为智能源自于学习、记忆、行动、感知、规划和认知之间错综复杂的相互作用（下图）。
2. Agent AI在多模态交互中的应用Agent AI在多模态交互中的应用广泛，包括机器人学、游戏和医疗保健系统等。
例如，在机器人学中，Agent AI能够解析人类的指令并执行高级任务；在游戏中，它能够根据玩家的行动和自然语言指令进行交互；在医疗保健中，Agent AI可以帮助诊断和患者护理。
这些应用展示了Agent AI跨领域和任务的显著能力，挑战了我们对学习和认知的理解。
Agent基础模型的构建1. Agent Transformer的多模态编码器Agent Transformer是一种基于变换器的多模态编码器（下图），它允许交互式代理基于多模态信息采取行动。
这个模型由三个预训练的子模块初始化：视觉模块、代理行动模块和语言模块。
这种设计使得代理能够预测完成机器人、游戏和交互式医疗任务所需的行动（或行动标记）。
2. Agent学习策略：强化学习与模仿学习Agent学习策略包括强化学习（RL）和模仿学习（IL）。
RL是一种基于奖励（或惩罚）来学习状态和行动之间最佳关系的框架，已被广泛应用于机器人学等领域。
IL则利用示范数据来模仿人类专家的行动，例如在机器人学中，通过行为克隆（BC）方法，机器人被训练来模仿专家在特定任务中的行动。
3. Agent系统中的优化问题Agent系统的优化问题可以分为空间和时间两个方面。
空间优化考虑代理在物理空间中执行任务的方式，包括机器人之间的协调、资源分配和保持有序的空间。
时间优化则关注代理随时间执行任务的方式，涉及任务调度、序列化和时间线效率。
4. 自我改进的Transformer模型当前基于基础模型的AI代理能够从多种不同的数据源中学习，这允许更灵活的数据来源用于训练。
自我改进的代理可以通过环境交互持续学习和改进，例如在机器人教学中，Agent AI根据人类提供的多模态指令理解其需要做什么，然后在虚拟世界中生成图像或场景，并利用用户反馈进行迭代改进，逐渐适应环境。
Agent AI的分类与研究Agent AI根据环境和动作内容两个维度可划分成四个类别（下图）。
环境分物理世界还是虚拟世界，而动作内容涉及低级别精细动作操控的，我们称之为“操控动作”（Manipulation action）；代理的动作可能主要旨在为机器人或人类的意图指令进行高级信息传递，我们称之为“意图动作”（Intentional action）。
1. 物理环境中的操控动作物理环境中的操控动作主要指在实体环境中进行物理互动的智能体，如机器人技术。
这类Agent的研究重点在于如何使机器人能够理解高层次的指令并将其分解为一系列的物理操控动作。
例如，Brohan等人提出的RT-1[1]和RT-2[2]模型，就是通过将一系列图像和语言输入转化为机器人基座和手臂的动作序列，展现了在机器人领域的高泛化性能（下图是RT-2模型示意图）。
2. 虚拟环境中的操控动作虚拟环境中的操控动作在模拟环境中进行学习和任务执行，如视频游戏中的智能体。
这些Agent的学习目标通常是在模拟环境内进行，而不是过渡到物理世界。
研究表明，基于大规模文本、图像和视频数据训练的通用视觉语言模型可以作为多模态Agent的基础，使其能够在不同环境中行动。
3. 物理环境中的意图动作物理环境中的意图动作是在实体环境中进行非物理互动，如在医疗保健领域的应用。
这些Agent能够理解用户的意图，检索临床知识，并在人与人的互动中发挥作用。
例如，Lee等人研究的医疗聊天机器人[3]，展示了利用大型语言模型进行病人诊断的潜力。
4. 虚拟环境中的意图动作虚拟环境中的意图动作在游戏、虚拟现实（VR）和扩展现实（XR）中创建互动内容。
这类Agent能够遵循指令进行导航，并在特定游戏中展现超人的表现。
例如，Meta Fundamental AI Research等人的研究表明，Agent AI在特定游戏中的表现超越了人类[4]。
5. 非实体化的多模态Agent分类非实体化的多模态Agent强调使用多模态信息进行有益的非实体化动作。
这类Agent需要具备高度的语言和视觉识别能力，利用大型基础模型来执行任务规划和逻辑推理等。
Agent AI的应用领域1. 机器人技术中的应用机器人作为典型的Agent，需要与环境有效互动。
例如，使用大型基础模型作为输入信息的编码器，指导机器人基于语言指令和视觉线索进行动作。
此外，LLMs的高级语言处理能力有助于推进任务规划技术[5]（下图是GRID模型示意图，利用指令、场景图和机器人图作为机器人任务规划的输入）。
2. 游戏领域的创新游戏提供了一个独特的沙盒环境，测试大型基础模型的合作和决策能力。
Agent AI在游戏中的应用，如NPC行为、人与NPC的互动以及游戏分析，都在推动游戏体验的革新。
3. 交互式医疗保健的潜力Agent AI在医疗保健中的应用，如诊断Agent和知识检索Agent，能够帮助患者和医生，通过理解用户意图、检索临床知识和把握正在进行的人际互动，提高医疗服务的可及性和质量。
4. 交云互动多模态任务的挑战Agent AI在多模态任务中的应用，包括图像和语言理解与生成、视频语言理解与生成等，这些任务对于开发能够与世界以更类似于人类的方式互动的AI代理至关重要。
部署Agent AI的未来方向1. 探索新范式Agent AI的未来发展需要探索新的范式，这意味着要超越现有的模型和算法，寻找更加综合和全面的方法来理解和处理信息。
这可能包括将不同模态的数据（如视觉、语言和传感器输入）整合到一个统一的框架中，以解决大规模模型中常见的幻觉和偏见问题，从而提高识别和响应能力。
2. 通用端到端系统未来的Agent AI系统将朝向构建通用的端到端模型发展，这些模型能够利用大规模数据进行训练，以适应多样化的应用场景。
这样的系统能够灵活地适应不同的任务和环境，从而推动AI解决方案的多功能性和适应性。
3. 模态间的接地方法通过跨模态信息的整合，我们可以提高数据处理的连贯性和效率。
例如，结合视觉和语言信息来理解和描述图像内容，或者利用历史行为数据来预测未来的动作。
这种方法有助于提高Agent AI系统的理解和响应能力。
4. 直观的人机界面开发直观的人机界面对于促进人与Agent AI之间的有效和有意义的互动至关重要。
这包括创建能够理解自然语言指令的系统，以及设计能够根据用户意图和环境反馈进行适应性响应的界面。
5. 控制LLM/VLM的偏见和幻觉为了控制大型语言模型（LLM）和视觉语言模型（VLM）的偏见和幻觉，研究人员正在探索新的方法，如使用检索增强的生成技术或其他外部知识检索机制。
这些方法旨在通过检索额外的源材料并提供机制来检查生成响应与源材料之间的矛盾，从而减少幻觉发生率。
6. 模拟与现实之间的桥梁所谓的"模拟到现实"问题强调了将在模拟环境中训练的AI代理部署到现实世界中的挑战。
为了解决这些问题，策略包括域随机化、域适应和改进模拟[6]的方法，以更好地准备模型应对现实世界的不可预测性。
下图就是文献提出的任务序列模拟器可为机器人操纵的学习和执行提供场景组合。
7. 多Agent互动的复杂性Agent AI交互目前仍然是一个复杂的过程，需要结合多种技能。
当前的人机交互系统在多代理环境中主要是基于规则的。
它们确实在一定程度上具有智能行为，并且具有一些网络知识。
在代理系统设计中实现特定行为的多代理互动非常重要。
8. Agent基础设施与系统的建设Agent AI的快速发展需要强大的基础设施来支持它们的训练、评估和部署。
在娱乐、研究和工业领域内，Agent AI社区正在迅速扩大。
构建高质量的代理基础设施对于使用先进硬件、多样化的数据来源和强大的软件库来开发多模态代理副驾驶员具有重要影响。
面向Agent AI的挑战1. 未结构化环境的适应性Agent AI需要能够适应未结构化的环境，这意味着它们必须能够处理视觉输入对于高级意图和低级动作的影响，即使在给定相同目标指令的情况下也是如此。
2. Agent的共情能力Agent AI需要具备共情能力，以便在开放式对象集中做出决策，这些对象集要求代理的决策模块使用难以手动编码的常识知识。
3. 多Agent互动与协作Agent AI需要能够理解和操作超出基于模板的命令，还要能够理解日常语言中表达的目标、约束和部分计划的上下文，以实现多代理互动和协作。
4. 大型Agent基础模型的新能力随着Agent AI领域的发展，我们需要开发出能够在新领域中进行微调/预训练的模型，以便它们能够处理在未见过的环境或情景中的泛化性能挑战。
这可能涉及到利用通用基础模型的知识-记忆来处理新颖场景，特别是在生成人类与代理之间的协作空间方面。
新兴能力与混合现实1. 交互式Agent的跨模态协作在混合现实的背景下，交互式Agent的跨模态协作是实现有效人机交互的关键。
这种协作涉及到Agent能够理解和响应来自不同感官模态的信息，比如视觉、听觉和触觉。
例如，一个机器人可能需要通过视觉模块识别物体，通过听觉模块理解人类的语音指令，再通过触觉模块与物理环境互动。
这种跨模态的信息处理能力，不仅要求Agent具备强大的感知能力，还要求其能够在不同模态之间进行有效的信息整合和决策。
2. 跨现实环境的适应性Agent在跨现实环境中的适应性是指其能够在物理世界和虚拟世界之间无缝切换并执行任务的能力。
这要求Agent不仅要能够理解和适应现实世界的物理规律，还要能够在虚拟环境中根据预设的规则行动。
例如，在虚拟现实游戏中，Agent需要根据游戏规则和玩家的互动来做出响应；而在现实世界中，同样的Agent可能需要根据物理定律和环境变化来操作机械臂完成任务。
这种能力的提升，不仅能够增强Agent的灵活性和适用范围，还能够为人类提供更加丰富和沉浸式的交互体验。
结论与展望1. Agent AI的未来发展Agent AI是个有前景的新兴领域，能在多领域发挥重要作用。
它具有整合性和适应性，能理解和执行自然语言指令，处理视听输入，在复杂环境中规划执行任务。
未来，它可能发展出类似“意识”的特性，更好地理解和预测环境变化，与人类用户深度交互。
同时，其在模拟环境中的自我改进能力提升后，能更好地适应现实世界，实现从模拟到现实的无缝过渡。
2. 对人工智能全面理解的贡献Agent AI的发展对全面理解人工智能有显著贡献。
它促进了跨学科研究，有助于探索智能体的认知和意识，为未来研究提供基础，鼓励广泛的社会参与。
随着技术发展，我们有望看到AI代理在复杂环境中扮演更动态、互动的角色，这是迈向AGI的关键一步。
Agent AI的进步有助于理解学习和认知过程，为实现全面智能体系提供新视角。
参考资料[1] Anthony Brohan, Noah Brown, Justice Carbajal, et al. 2022. Rt-1: Robotics transformer for real-world control at scale. arXiv preprint arXiv:2212.06817. 5, 6, 7[2] Anthony Brohan, Noah Brown, Justice Carbajal, et al. 2023. Rt-2: Vision-language-action models transfer web knowledge to robotic control. arXiv preprint arXiv:2307.15818. 5, 6, 7, 21[3] Peter Lee, Sebastien Bubeck, and Joseph Petro. 2023. Benefits, limits, and risks of gpt-4 as an ai chatbot for medicine. New England Journal of Medicine, 388(13):1233–1239. 7, 9[4] Meta Fundamental AI Research, Anton Bakhtin, Noam Brown, Emily Dinan, et al. 2022. Human-level play in the game of Diplomacy by combining language models with strategic reasoning. Science, 378(6624):1067–1074. 7[5] Zhe Ni, Xiao-Xin Deng, Cong Tai, Xin-Yue Zhu, Xiang Wu, Yong-Jin Liu, and Long Zeng. 2023. Grid: Scene-graph-based instruction-driven robotic task planning. arXiv preprint arXiv:2309.07726. 7[6] Kazuhiro Sasabuchi, Daichi Saito, Atsushi Kanehira, Naoki Wake, Jun Takamatsu, and Katsushi Ikeuchi. 2023. Task-sequencing simulator: Integrated machine learning to execution simulation for robot manipulation. arXiv preprint arXiv:2301.01382. 10 预览时标签不可点